{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "987d3d7984d641459a25e95ba15c08fe",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": []
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bd2c8e0a09f6430e91d7ee400a517e42",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "9d2836ad34c7426f9827f16cfbb946ea",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1120,
    "execution_start": 1706785991242,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "2b453cd7374248459e31d8a46755d22a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1755,
    "execution_start": 1706785994333,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "53e74a04978344e398acb9719112ec0d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1706785998018,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Define color mapping for plotting\n",
    "color_mapping = {\n",
    "    \"Bollen\": \"black\",\n",
    "    \"Mod_Bauer\": \"blue\",\n",
    "    \"Mizumoto\": \"red\",\n",
    "    \"NESMS\": \"purple\",\n",
    "    \"Orig_Bauer\": \"gold\",\n",
    "    \"OSRI\": \"lime\",\n",
    "    \"PathFx\": \"magenta\",\n",
    "    \"Rev_Kat_individual\": \"orange\",\n",
    "    \"Rev_Kat_grouped\": \"teal\",\n",
    "    \"Rev_Toku\": \"cyan\",\n",
    "    \"Tomita\": \"olive\",\n",
    "    \"van_der_Linden\": \"brown\",\n",
    "    \"SORG\": \"pink\"}\n",
    "\n",
    "# List of algorithms and time periods\n",
    "algorithms = [\"Bollen\", \"Mod_Bauer\", \"Mizumoto\", \"NESMS\", \"Orig_Bauer\", \n",
    "              \"OSRI\", \"PathFx\", \"Rev_Kat_individual\", \"Rev_Kat_grouped\", \"Rev_Toku\",\n",
    "              \"Tomita\", \"van_der_Linden\", \"SORG\"]\n",
    "periods = [\"3_months\", \"6_months\", \"12_months\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "51c2c2fcdac54a1eb9f5e7ef79f310f4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10,
    "execution_start": 1706786000527,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Making sure probabilities are between 0 and 1\n",
    "for algorithm in algorithms:\n",
    "    for period in periods:\n",
    "        df[f\"{algorithm}_{period}\"] = (df[f\"{algorithm}_{period}\"])/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metric_statistics(scores):\n",
    "    \"\"\"\n",
    "    Calculate and return the mean and 95% confidence interval for a list of scores.\n",
    "    \n",
    "    Parameters:\n",
    "    scores (array-like): A list or array of numerical scores for which the statistics are to be calculated.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - mean_score (float): The mean (average) of the scores, rounded to two decimal places.\n",
    "        - lower_ci (float): The lower bound of the 95% confidence interval (2.5th percentile), rounded to two decimal places.\n",
    "        - upper_ci (float): The upper bound of the 95% confidence interval (97.5th percentile), rounded to two decimal places.\n",
    "    \"\"\"\n",
    "\n",
    "    LOWER_PERCENTILE = 2.5\n",
    "    UPPER_PERCENTILE = 97.5\n",
    "\n",
    "    sorted_scores = np.sort(scores)\n",
    "    mean_score = round(np.mean(sorted_scores), 2)\n",
    "    lower_ci = round(np.percentile(sorted_scores, LOWER_PERCENTILE), 2)\n",
    "    upper_ci = round(np.percentile(sorted_scores, UPPER_PERCENTILE), 2)\n",
    "    return mean_score, lower_ci, upper_ci\n",
    "\n",
    "def logit(p):\n",
    "    \"\"\"\n",
    "    Compute the logit (log-odds) of the given probabilities.\n",
    "    \n",
    "    This function calculates the logit, or the natural logarithm of the odds, for each probability in the input.\n",
    "    Probabilities are clipped to avoid issues with extreme values (0% or 100%).\n",
    "\n",
    "    Parameters:\n",
    "    p (array-like): An array of probabilities (values between 0 and 1).\n",
    "\n",
    "    Returns:\n",
    "    array: An array of logit values corresponding to the input probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    clipped_p = np.clip(p, 1e-15, 1 - 1e-15)\n",
    "    return np.log(clipped_p / (1 - clipped_p)).values\n",
    "\n",
    "def calibration_intercept_slope(y_true, y_pred_proba):\n",
    "    \"\"\"\n",
    "    Calculate the calibration intercept and slope for predicted probabilities.\n",
    "\n",
    "    This function fits a logistic regression model to the predicted probabilities to determine the calibration\n",
    "    intercept and slope. The intercept and slope provide insight into the calibration of the predicted probabilities\n",
    "    compared to the true outcomes.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (array-like): An array of true binary outcomes (0 or 1).\n",
    "    y_pred_proba (array-like): An array of predicted probabilities for the positive class.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - intercept (float): The intercept of the logistic regression model.\n",
    "        - slope (float): The slope of the logistic regression model.\n",
    "    \"\"\"\n",
    "    # Fit logistic regression to predicted probabilities\n",
    "    log_odds = logit(y_pred_proba)\n",
    "    \n",
    "    lr = LogisticRegression(penalty=None)\n",
    "    lr.fit(log_odds.reshape(-1, 1), y_true)\n",
    "    \n",
    "    # Intercept and slope\n",
    "    intercept = lr.intercept_[0]\n",
    "    slope = lr.coef_[0][0]\n",
    "    \n",
    "    return intercept, slope\n",
    "\n",
    "def calc_measures(y_actual, y_pred_prob, algorithm):\n",
    "    \"\"\"\n",
    "    Calculate performance measures for a given set of predicted probabilities using bootstrapping.\n",
    "\n",
    "    This function performs bootstrapping to estimate the performance metrics including AUC, calibration intercept,\n",
    "    calibration slope, and Brier score. It calculates the mean and confidence intervals for these metrics over \n",
    "    multiple bootstrap samples.\n",
    "\n",
    "    Parameters:\n",
    "    y_actual (array-like): An array of true binary outcomes (0 or 1).\n",
    "    y_pred_prob (array-like): An array of predicted probabilities for the positive class.\n",
    "    algorithm (str): The name of the algorithm being evaluated.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the mean and confidence intervals for AUC, calibration intercept,\n",
    "                  calibration slope, and Brier score, labeled with the name of the algorithm.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Bootstraps\n",
    "    n_bootstraps = 2000\n",
    "\n",
    "    # Set empty lists\n",
    "    auc_scores = []\n",
    "    calibration_intercepts = []\n",
    "    calibration_slopes = []\n",
    "    brier_scores = []\n",
    "    \n",
    "    # Bootstrap loop\n",
    "    for i in range(n_bootstraps):\n",
    "        # Bootstrap by sampling with replacement on the prediction indices, stratified on y_actual\n",
    "        y_actual_boot, y_pred_prob_boot = resample(y_actual, y_pred_prob, \n",
    "                                                     replace=True, \n",
    "                                                     n_samples=len(y_actual), \n",
    "                                                     stratify=y_actual,\n",
    "                                                     random_state=i)\n",
    "                \n",
    "        # Discrimination\n",
    "        auc_scores.append(roc_auc_score(y_actual_boot, y_pred_prob_boot))\n",
    "        \n",
    "        # Calibration\n",
    "        intercept, slope = calibration_intercept_slope(y_actual_boot, y_pred_prob_boot)\n",
    "        calibration_intercepts.append(intercept)\n",
    "        calibration_slopes.append(slope)\n",
    "        \n",
    "        # Brier score\n",
    "        brier_scores.append(brier_score_loss(y_actual_boot, y_pred_prob_boot))\n",
    "\n",
    "    # Calculate mean and confidence intervals (AUC, Calibration Intercept & Slope)\n",
    "    auc_stat = calculate_metric_statistics(auc_scores)\n",
    "    intercept_stat = calculate_metric_statistics(calibration_intercepts)\n",
    "    slope_stat = calculate_metric_statistics(calibration_slopes)\n",
    "    brier_stat = calculate_metric_statistics(brier_scores)\n",
    "\n",
    "    # Compile results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Algorithm': f\"{algorithm}\",\n",
    "        'auc_score': [f\"{auc_stat[0]} ({auc_stat[1]} - {auc_stat[2]})\"],\n",
    "        'calibration_intercept': [f\"{intercept_stat[0]} ({intercept_stat[1]} - {intercept_stat[2]})\"],\n",
    "        'calibration_slope': [f\"{slope_stat[0]} ({slope_stat[1]} - {slope_stat[2]})\"],\n",
    "        'brier_score': [f\"{brier_stat[0]} ({brier_stat[1]} - {brier_stat[2]})\"]})\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of models for 3, 6, and 12 months survival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "221a900c7680426e84a52ede99bb0069",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 106973,
    "execution_start": 1706786006063,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "results_3_months = pd.DataFrame()\n",
    "for algorithm in algorithms:\n",
    "    col_name = algorithm + \"_3_months\"\n",
    "    result = calc_measures(df[\"3_months\"], df[col_name], algorithm)\n",
    "    results_3_months = pd.concat([results_3_months, result], ignore_index=True)\n",
    "results_3_months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "26f2d050c0c74619b9258aeac9324fac",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 109862,
    "execution_start": 1706786113074,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "results_6_months = pd.DataFrame()\n",
    "for algorithm in algorithms:\n",
    "    if algorithm == \"SORG\":\n",
    "        continue  # Skip SORG algorithm (no SORG prediction at 6_months)\n",
    "\n",
    "    col_name = algorithm + \"_6_months\"\n",
    "    result = calc_measures(df[\"6_months\"], df[col_name], algorithm)\n",
    "    results_6_months = pd.concat([results_6_months, result], ignore_index=True)\n",
    "results_6_months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "3104fd36b2c645f59e492364c1197a3b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 112314,
    "execution_start": 1706786222974,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "results_12_months = pd.DataFrame()\n",
    "for algorithm in algorithms:\n",
    "    col_name = algorithm + \"_12_months\"\n",
    "    result = calc_measures(df[\"12_months\"], df[col_name], algorithm)\n",
    "    results_12_months = pd.concat([results_12_months, result], ignore_index=True)\n",
    "results_12_months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "64aafd0436a4472f803a144cf590f811",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "38ab6fb32e494f2bbb0c557b53ee3eeb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 662,
    "execution_start": 1706786509682,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "results_3_months.to_excel(\"Data_3_months\")\n",
    "results_6_months.to_excel(\"Data_6_months\")\n",
    "results_12_months.to_excel(\"Data_12_months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "72a60361cb834850b8c72a16eab8714c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 691,
    "execution_start": 1706786523338,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    'results_3_months': pd.read_excel(\"Data_3_months\"),\n",
    "    'results_6_months': pd.read_excel(\"Data_6_months\"),\n",
    "    'results_12_months': pd.read_excel(\"Data_12_months\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete case analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define algorithms to perform complete case analysis on\n",
    "algorithms = [\"Mizumoto\", \"NESMS\", \"PathFx\", \"Rev_Kat_grouped\", \"Rev_Kat_individual\", \"SORG\"]\n",
    "periods = [\"3_months\", \"6_months\", \"12_months\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algorithm in algorithms:\n",
    "    # Load the dataset\n",
    "    df = pd.read_excel(rf\"Data_algorithm_completecases\") # Make sure you select complete cases seperate for each algorithm\n",
    "\n",
    "    # Initialize an empty dictionary to store DataFrames for each timepoint\n",
    "    results_dict = {}\n",
    "\n",
    "    for period in periods:\n",
    "        if algorithm == \"SORG\" and period == \"6_months\":\n",
    "            continue # Skip SORG algorithm (no SORG prediction at 6_months)\n",
    "            \n",
    "        col_name = f\"{algorithm}_{period}\"\n",
    "        df[col_name] = df[col_name]/100\n",
    "        result = calc_measures(df[period], df[col_name], algorithm)\n",
    "        results_dict[period] = result\n",
    "\n",
    "    # Create a new Excel writer\n",
    "    writer = pd.ExcelWriter(rf'Results\\Complete case analysis\\{algorithm}.xlsx', engine='xlsxwriter')\n",
    "\n",
    "    # Write each DataFrame to a separate sheet\n",
    "    for period, result in results_dict.items():\n",
    "        result.to_excel(writer, sheet_name=period)\n",
    "\n",
    "    # Save the Excel file\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "24a81b2d61a1475a97bc56833c544d6f",
  "deepnote_persisted_session": {
   "createdAt": "2024-02-01T11:40:58.699Z"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
